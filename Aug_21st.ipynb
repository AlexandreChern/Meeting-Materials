{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meeting August 21st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One weird GPU bug when launching kernel\n",
    "\n",
    "```\n",
    "ERROR: CUDA error: an illegal memory access was encountered (code 700, ERROR_ILLEGAL_ADDRESS)\n",
    "```\n",
    "\n",
    "After encountering this bug, I need to restart Julia because this bug would be reported for all other GPU kernel functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory through-put of D2y\n",
    "\n",
    "I think this is ideal enough\n",
    "```\n",
    "julia> tester_D2y(2000)\n",
    "y ≈ y_gpu = true\n",
    "y ≈ y_gpu_2 = true\n",
    "y ≈ y_gpu_7 = true\n",
    "Float64(t1) = 4.43101793e8\n",
    "Float64(t2) = 4.64824109e8\n",
    "Float64(t3) = 5.526723e6\n",
    "Float64(t7) = 5.161289e6\n",
    "t1 / t2 = 0.9532676649523788\n",
    "t1 / t3 = 80.17441673845424\n",
    "t1 / t7 = 85.85099439306731\n",
    "CPU Through-put                 1.44\n",
    "GPU Through-put                 1.38\n",
    "GPU (v2) Through-put               115.80\n",
    "GPU (v7) Through-put               124.00\n",
    "(4.43101793e8, 4.64824109e8, 5.526723e6)\n",
    "\n",
    "\n",
    "julia> tester_D2y(10000)\n",
    "y ≈ y_gpu = true\n",
    "y ≈ y_gpu_2 = true\n",
    "y ≈ y_gpu_7 = true\n",
    "Float64(t1) = 2.6545772606e10\n",
    "Float64(t2) = 5.8792959517e10\n",
    "Float64(t3) = 1.3529684e8\n",
    "Float64(t7) = 1.2718651e8\n",
    "t1 / t2 = 0.4515127801709707\n",
    "t1 / t3 = 196.2039365147035\n",
    "t1 / t7 = 208.71531584599657\n",
    "CPU Through-put                 0.60\n",
    "GPU Through-put                 0.27\n",
    "GPU (v2) Through-put               118.26\n",
    "GPU (v7) Through-put               125.80\n",
    "(2.6545772606e10, 5.8792959517e10, 1.3529684e8, 1.2718651e8)\n",
    "```\n",
    "\n",
    "for Nx=Ny= 10000\n",
    "Time for D2y() (matrix-free on CPU): 26.5s\n",
    "Time for D2x() (matrix-free on GPU with shared memory): 0.127s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: @cuStaticSharedMem not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: @cuStaticSharedMem not defined",
      ""
     ]
    }
   ],
   "source": [
    "function D2y_GPU_v7(d_u, d_y, Nx, Ny, h, ::Val{TILE_DIM1}, ::Val{TILE_DIM2}) where {TILE_DIM1, TILE_DIM2}\n",
    "\ttidx = threadIdx().x\n",
    "\ttidy = threadIdx().y\n",
    "\n",
    "\ti = (blockIdx().x - 1) * TILE_DIM1 + tidx\n",
    "\tj = (blockIdx().y - 1) * TILE_DIM2 + tidy\n",
    "\n",
    "\tglobal_index = i + (j-1)*Nx\n",
    "\n",
    "\tHALO_WIDTH = 1\n",
    "\ttile = @cuStaticSharedMem(eltype(d_u),(TILE_DIM1+2*HALO_WIDTH,TILE_DIM2))\n",
    "\n",
    "\tk = tidx\n",
    "\tl = tidy\n",
    "\n",
    "\t# Writing pencil-shaped shared memory\n",
    "\n",
    "\t# for tile itself\n",
    "\tif k <= TILE_DIM1 && l <= TILE_DIM2 && global_index <= Nx*Ny\n",
    "\t\ttile[k+HALO_WIDTH,l] = d_u[global_index]\n",
    "\tend\n",
    "\n",
    "\tsync_threads()\n",
    "\n",
    "\t# For upper halo\n",
    "\tif k <= HALO_WIDTH && l <= TILE_DIM2 && HALO_WIDTH + 1 <= global_index <= Nx*Ny + HALO_WIDTH\n",
    "\t\ttile[k,l] = d_u[global_index - HALO_WIDTH]\n",
    "\tend\n",
    "\n",
    "\tsync_threads()\n",
    "\n",
    "\t# For lower halo\n",
    "\tif k >= TILE_DIM1 - HALO_WIDTH && l <= TILE_DIM2 && HALO_WIDTH + 1 <= global_index <= Nx*Ny - HALO_WIDTH\n",
    "\t\ttile[k+2*HALO_WIDTH,l] = d_u[global_index + HALO_WIDTH]\n",
    "\tend\n",
    "\n",
    "\tsync_threads()\n",
    "\n",
    "\n",
    "\t# Finite Difference Operations starts here\n",
    "\n",
    "\t#Upper Boundary\n",
    "\tif k + HALO_WIDTH <= TILE_DIM1 + 2*HALO_WIDTH && l <= TILE_DIM2 && i == 1 && j <= Ny\n",
    "\t\td_y[global_index] = (tile[k+HALO_WIDTH,l] - 2*tile[k+HALO_WIDTH+1,l] + tile[k+HALO_WIDTH+2,l]) / h^2\n",
    "\tend\n",
    "\n",
    "\tsync_threads()\n",
    "\n",
    "\t#Center\n",
    "\tif k + HALO_WIDTH <= TILE_DIM1 + 2*HALO_WIDTH && l <= TILE_DIM2 && 2 <= i <= Nx-1 && j <= Ny\n",
    "\t\td_y[global_index] = (tile[k+HALO_WIDTH-1,l] - 2*tile[k+HALO_WIDTH,l] + tile[k+HALO_WIDTH+1,l]) / h^2\n",
    "\tend\n",
    "\n",
    "\tsync_threads()\n",
    "\n",
    "\t#Lower Boundary\n",
    "\tif k + HALO_WIDTH <= TILE_DIM1 + 2*HALO_WIDTH && l <= TILE_DIM2 && i == Nx && j <= Ny\n",
    "\t\td_y[global_index] = (tile[k+HALO_WIDTH-2,l] - 2*tile[k+HALO_WIDTH-1,l] + tile[k+HALO_WIDTH,l]) / h^2\n",
    "\tend\n",
    "\n",
    "\tsync_threads()\n",
    "\t\n",
    "\tnothing\n",
    "\n",
    "end\n",
    "\n",
    "function tester_D2y(Nx)\n",
    "\t# Nx = Ny = 1000;\n",
    "\tNy = Nx\n",
    "\tu = randn(Nx * Ny)\n",
    "\td_u = CuArray(u)\n",
    "\td_y = similar(d_u)\n",
    "\td_y2 = similar(d_u)\n",
    "\td_y7 = similar(d_u)\n",
    "\th = 1/Nx\n",
    "\tTILE_DIM=32\n",
    "\tt1 = 0\n",
    "\tt2 = 0\n",
    "\tt3 = 0\n",
    "\n",
    "\tTILE_DIM_1 = 16\n",
    "\tTILE_DIM_2 = 4\n",
    "\n",
    "\trep_times = 10\n",
    "\n",
    "\tTHREAD_NUM = 32\n",
    "\tBLOCK_NUM = div(Nx * Ny,TILE_DIM) + 1\n",
    "\n",
    "\tgriddim = (div(Nx,TILE_DIM_1)+1,div(Ny,TILE_DIM_2)+1)\n",
    "\tblockdim = (TILE_DIM_1,TILE_DIM_2)\n",
    "\n",
    "\ty = D2y(u,Nx,Ny,h)\n",
    "\t@cuda threads=THREAD_NUM blocks=BLOCK_NUM D2y_GPU(d_u,d_y,Nx,Ny,h,Val(TILE_DIM))\n",
    "\ty_gpu = collect(d_y)\n",
    "\t@cuda threads=THREAD_NUM blocks=BLOCK_NUM D2y_GPU_v5(d_u,d_y2,Nx,Ny,h,Val(TILE_DIM))\n",
    "\tsynchronize()\n",
    "\ty_gpu_2 = collect(d_y2)\n",
    "\t@cuda threads=blockdim blocks=griddim D2y_GPU_v7(d_u,d_y7, Nx, Ny, h, Val(TILE_DIM_1), Val(TILE_DIM_2))\n",
    "\ty_gpu_7 = collect(d_y7)\n",
    "\t# @show y_gpu - y\n",
    "\t# @show y_gpu_2 - y\n",
    "\t@show y ≈ y_gpu\n",
    "\t@show y ≈ y_gpu_2\n",
    "\t@show y ≈ y_gpu_7\n",
    "\n",
    "\n",
    "\tty = time_ns()\n",
    "\tfor i in 1:rep_times\n",
    "\t\ty = D2x(u,Nx,Ny,h)\n",
    "\tend\n",
    "\tty_end = time_ns()\n",
    "\tt1 = ty_end - ty\n",
    "\tt_dy = time_ns()\n",
    "\tfor i in 1:rep_times\n",
    "\t\t@cuda threads=THREAD_NUM blocks=BLOCK_NUM D2y_GPU(d_u,d_y,Nx,Ny,h,Val(TILE_DIM))\n",
    "\tend\n",
    "\tsynchronize()\n",
    "\t# sync_threads()\n",
    "\tt_dy_end = time_ns()\n",
    "\tt2 = t_dy_end - t_dy\n",
    "\n",
    "\tt_dy_v2 = time_ns()\n",
    "\tfor i in 1:rep_times\n",
    "\t\t@cuda threads=THREAD_NUM blocks=BLOCK_NUM D2y_GPU_v5(d_u,d_y2,Nx,Ny,h,Val(TILE_DIM))\n",
    "\tend\n",
    "\tsynchronize()\n",
    "\t# sync_threads()\n",
    "\tt_dy_v2_end = time_ns()\n",
    "\tt3 = t_dy_v2_end - t_dy_v2\n",
    "\n",
    "\tt_dy_v7 = time_ns()\n",
    "\tfor i in 1:rep_times\n",
    "\t\t@cuda threads=blockdim blocks=griddim D2y_GPU_v7(d_u,d_y7, Nx, Ny, h, Val(TILE_DIM_1), Val(TILE_DIM_2))\n",
    "\tend\n",
    "\tsynchronize()\n",
    "\tt_dy_v7_end = time_ns()\n",
    "\tt7 = t_dy_v7_end - t_dy_v7\n",
    "\n",
    "\t@show Float64(t1)\n",
    "\t@show Float64(t2)\n",
    "\t@show Float64(t3)\n",
    "\t@show Float64(t7)\n",
    "\n",
    "\t@show t1/t2\n",
    "\t@show t1/t3\n",
    "\t@show t1/t7\n",
    "\n",
    "\tmemsize = length(u) * sizeof(eltype(u))\n",
    "\t@printf(\"CPU Through-put %20.2f\\n\", 2 * memsize * rep_times / t1)\n",
    "\t@printf(\"GPU Through-put %20.2f\\n\", 2 * memsize * rep_times / t2)\n",
    "\t@printf(\"GPU (v2) Through-put %20.2f\\n\", 2 * memsize * rep_times / t3)\n",
    "\t@printf(\"GPU (v7) Through-put %20.2f\\n\", 2 * memsize * rep_times / t7)\n",
    "\n",
    "\treturn Float64(t1), Float64(t2), Float64(t3), Float64(t7)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unrolling does not have better performance here\n",
    "\n",
    "```\n",
    "UNROLL_NUM = 0\n",
    "\n",
    "\t@unroll for m = 0:UNROLL_NUM\n",
    "\t\tif k + m <= TILE_DIM1 && l <= TILE_DIM2 # &&  global_index <= Nx*Ny\n",
    "\t\t\t@inbounds tile[tidx+m, tidy+HALO_WIDTH] = d_u[global_index + m]\n",
    "\t\tend\n",
    "\tend\n",
    "\n",
    "```\n",
    "\n",
    "Unrolling for reading data into shared memory in D2x_GPU(), through-put decreases as we increase UNROLL_NUM (UNROLL_NUM <= TILE_DIM1 - 1)\n",
    "\n",
    "\n",
    "```\n",
    "\tif global_index <= Nx*Ny\n",
    "\t\td_y[global_index] = tile[k+HALO_WIDTH,l]\n",
    "\tend # Check if copying data to tile is correct, checked\n",
    "\n",
    "\tUNROLL_NUM = TILE_DIM2 - 1\n",
    "\n",
    "\tfor m = 1:UNROLL_NUM\n",
    "\t\tif k + HALO_WIDTH <= TILE_DIM1 + 2*HALO_WIDTH && l+m <= TILE_DIM2 && i == 1 && j <= Ny\n",
    "\t\t\td_y[global_index + m*Nx] = (tile[k+HALO_WIDTH,l+m] - 2*tile[k+HALO_WIDTH+1,l+m] + tile[k+HALO_WIDTH+2,l+m]) / h^2\n",
    "\t\tend\n",
    "\n",
    "\t\tif k + HALO_WIDTH <= TILE_DIM1 + 2*HALO_WIDTH && l+m <= TILE_DIM2 && 2 <= i <= Nx-1 && j <= Ny\n",
    "\t\t\td_y[global_index + m*Nx] = (tile[k+HALO_WIDTH-1,l+m] - 2*tile[k+HALO_WIDTH,l+m] + tile[k+HALO_WIDTH+1,l+m]) / h^2\n",
    "\t\tend\n",
    "\n",
    "\t\tif k + HALO_WIDTH <= TILE_DIM1 + 2*HALO_WIDTH && l+m <= TILE_DIM2 && i == Nx && j <= Ny\n",
    "\t\t\td_y[global_index + m*Nx] = (tile[k+HALO_WIDTH-2,l+m] - 2*tile[k+HALO_WIDTH-1,l+m] + tile[k+HALO_WIDTH,l+m]) / h^2\n",
    "\t\tend\n",
    "\tend\n",
    "```\n",
    "\n",
    "Unrolling for calculating derivatives using shared memory in D2y_GPU(), through-put decreases as we increase UNROLL_NUM (UNROLL_NUM <= TILE_DIM2 - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance using different shapes of pencil. D2y_GPU(), Nx = Ny = 2000\n",
    "\n",
    "\n",
    "| TILE_DIM1 | TILE_DIM2 | Through-put (GB/s)|\n",
    "| ---------  |  --------- | --------- |\n",
    "| 16       |    16    |   116    |\n",
    "| 16       |    8    |     121   |\n",
    "| 16       |    4    |   125 |\n",
    "| 16       |    2    |    86  |\n",
    "| 16       |    1    |    47   |\n",
    "|  64      |    4    |     115    |\n",
    "|  32      |    4    |     120    |\n",
    "|  16      |    4    |     125    |\n",
    "|  8       |    4    |     81     | \n",
    "|  4       |    4    |     45     |\n",
    "| 64       |    1    |    122     |\n",
    "| 32       |    2    |    122     |\n",
    "| 16       |    4    |    125     |\n",
    "| 8        |    8    |    125     |\n",
    "| 4        |   16    |    122     |\n",
    "| 2        |   32    |   105      |\n",
    "\n",
    "\n",
    "From the table, it seems that the total size of the pencil affects the performance most, and the shape of the pencil affects the performance less.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Matrix-free functions in 1 kernel\n",
    "\n",
    "```\n",
    "function Operator_y_GPU(d_u, d_y, d2_y, Nx, Ny, h, ::Val{TILE_DIM1}, ::Val{TILE_DIM2}) where {TILE_DIM1, TILE_DIM2}\n",
    "\ttidx = threadIdx().x\n",
    "\ttidy = threadIdx().y\n",
    "\n",
    "\ti = (blockIdx().x - 1) * TILE_DIM1 + tidx\n",
    "\tj = (blockIdx().y - 1) * TILE_DIM2 + tidy\n",
    "\n",
    "\tglobal_index = i + (j-1)*Nx\n",
    "\n",
    "\tHALO_WIDTH = 1\n",
    "\ttile = @cuStaticSharedMem(eltype(d_u),(TILE_DIM1+2*HALO_WIDTH,TILE_DIM2))\n",
    "\n",
    "\tk = tidx\n",
    "\tl = tidy\n",
    "\n",
    "\t# Writing pencil-shaped shared memory\n",
    "\n",
    "\t# for tile itself\n",
    "\tif k <= TILE_DIM1 && l <= TILE_DIM2 && global_index <= Nx*Ny\n",
    "\t\t@inbounds tile[k+HALO_WIDTH,l] = d_u[global_index]\n",
    "\tend\n",
    "\n",
    "\tsync_threads()\n",
    "\n",
    "\t# For upper halo\n",
    "\tif k <= HALO_WIDTH && l <= TILE_DIM2 && HALO_WIDTH + 1 <= global_index <= Nx*Ny + HALO_WIDTH\n",
    "\t\t@inbounds tile[k,l] = d_u[global_index - HALO_WIDTH]\n",
    "\tend\n",
    "\n",
    "\tsync_threads()\n",
    "\n",
    "\t# For lower halo\n",
    "\tif k >= TILE_DIM1 - HALO_WIDTH && l <= TILE_DIM2 && HALO_WIDTH + 1 <= global_index <= Nx*Ny - HALO_WIDTH\n",
    "\t\t@inbounds tile[k+2*HALO_WIDTH,l] = d_u[global_index + HALO_WIDTH]\n",
    "\tend\n",
    "\n",
    "\tsync_threads()\n",
    "\n",
    "\t# Finite Difference Operations starts here\n",
    "\n",
    "\t# For d2_y, output second order differential operators in y direction\n",
    "\n",
    "\t#Upper Boundary\n",
    "\tif k + HALO_WIDTH <= TILE_DIM1 + 2*HALO_WIDTH && l <= TILE_DIM2 && i == 1 && j <= Ny\n",
    "\t\t@inbounds d2_y[global_index] = (tile[k+HALO_WIDTH,l] - 2*tile[k+HALO_WIDTH+1,l] + tile[k+HALO_WIDTH+2,l]) / h^2\n",
    "\t\t@inbounds d_y[global_index] = (tile[k+HALO_WIDTH+1,l] - tile[k+HALO_WIDTH,l]) / h\n",
    "\tend\n",
    "\n",
    "\tsync_threads()\n",
    "\n",
    "\t#Center\n",
    "\tif k + HALO_WIDTH <= TILE_DIM1 + 2*HALO_WIDTH && l <= TILE_DIM2 && 2 <= i <= Nx-1 && j <= Ny\n",
    "\t\t@inbounds d2_y[global_index] = (tile[k+HALO_WIDTH-1,l] - 2*tile[k+HALO_WIDTH,l] + tile[k+HALO_WIDTH+1,l]) / h^2\n",
    "\t\t@inbounds d_y[global_index] = (tile[k+HALO_WIDTH+1,l] - tile[k+HALO_WIDTH-1,l]) / (2*h)\n",
    "\tend\n",
    "\n",
    "\tsync_threads()\n",
    "\n",
    "\t#Lower Boundary\n",
    "\tif k + HALO_WIDTH <= TILE_DIM1 + 2*HALO_WIDTH && l <= TILE_DIM2 && i == Nx && j <= Ny\n",
    "\t\t@inbounds d2_y[global_index] = (tile[k+HALO_WIDTH-2,l] - 2*tile[k+HALO_WIDTH-1,l] + tile[k+HALO_WIDTH,l]) / h^2\n",
    "\t\t@inbounds d_y[global_index] = (tile[k+HALO_WIDTH,l] - tile[k+HALO_WIDTH-1,l]) / h\n",
    "\tend\n",
    "\n",
    "\t# For d_y, output first order differential operators in y direction\n",
    "\n",
    "\t# if k + HALO_WIDTH <= TILE_DIM1 + 2*HALO_WIDTH && l <= TILE_DIM2 && i == 1 && j <= Ny\n",
    "\t# \td_y[global_index] = (tile[k+HALO_WIDTH+2,l] - tile[k+HALO_WIDTH+1]) / h\n",
    "\t# end\n",
    "\n",
    "\tnothing\n",
    "end\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "function tester_Operator_y_GPU(Nx)\n",
    "\tNy = Nx\n",
    "\th = 1/Nx\n",
    "\tTILE_DIM_1 = 16\n",
    "\tTILE_DIM_2 = 4\n",
    "\n",
    "\tu = randn(Nx*Ny)\n",
    "\td_u = CuArray(u)\n",
    "\td_y = similar(d_u)\n",
    "\td2_y = similar(d_u)\n",
    "\td_y7 = similar(d_u)\n",
    "\ty = Dy(u,Nx,Ny,h)\n",
    "\ty2 = D2y(u,Nx,Ny,h)\n",
    "\n",
    "\tgriddim = (div(Nx,TILE_DIM_1) + 1, div(Ny,TILE_DIM_2) + 1)\n",
    "\tblockdim = (TILE_DIM_1,TILE_DIM_2)\n",
    "\n",
    "\tTILE_DIM = 32\n",
    "\tTHREAD_NUM = 32\n",
    "\tBLOCK_NUM = div(Nx * Ny,TILE_DIM) + 1\n",
    "\n",
    "\t@cuda threads=blockdim blocks=griddim Operator_y_GPU(d_u,d_y, d2_y, Nx,Ny,h,Val(TILE_DIM_1),Val(TILE_DIM_2))\n",
    "\t@show Array(d_y) ≈ Array(y)\n",
    "\t@show Array(d2_y) ≈ Array(y2)\n",
    "\n",
    "\n",
    "\t# Starting test\n",
    "\n",
    "\trep_times = 10\n",
    "\n",
    "\tty = time_ns()\n",
    "\tfor i in 1:rep_times\n",
    "\t\ty = Dy(u,Nx,Ny,h)\n",
    "\tend\n",
    "\tty_end = time_ns()\n",
    "\tt1 = ty_end - ty\n",
    "\n",
    "\tmemsize = length(u) * sizeof(eltype(u))\n",
    "\t@printf(\"CPU Through-put (Dy) %20.2f\\n\", 2 * memsize * rep_times / t1)\n",
    "\n",
    "\tt2y = time_ns()\n",
    "\tfor i in 1:rep_times\n",
    "\t\ty2 = D2y(u,Nx,Ny,h)\n",
    "\tend\n",
    "\tt2y_end = time_ns()\n",
    "\tt2 = t2y_end - t2y\n",
    "\n",
    "\t@printf(\"CPU Through-put (D2y) %20.2f\\n\", 2 * memsize * rep_times / t1)\n",
    "\t@printf(\"CPU through-put (Dy + D2y, serial) %20.2f\\n\", 2 * memsize * rep_times / (t1+t2))\n",
    "\n",
    "\ttd2y = time_ns()\n",
    "\tfor i in 1:rep_times\n",
    "\t\t@cuda threads=blockdim blocks=griddim D2y_GPU_v7(d_u,d_y7, Nx, Ny, h, Val(TILE_DIM_1), Val(TILE_DIM_2))\n",
    "\tend\n",
    "\tsynchronize()\n",
    "\ttd2y_end = time_ns()\n",
    "\tt3 = td2y_end - td2y\n",
    "\t@printf(\"GPU through-put (D2y_GPU_v7) %20.2f\\n\", 2 * memsize * rep_times / t3)\n",
    "\n",
    "\tt_GPUy = time_ns()\n",
    "\tfor i in 1:rep_times\n",
    "\t\t@cuda threads=blockdim blocks=griddim Operator_y_GPU(d_u,d_y, d2_y, Nx,Ny,h,Val(TILE_DIM_1),Val(TILE_DIM_2))\n",
    "\tend\n",
    "\tsynchronize()\n",
    "\tt_GPUy_end = time_ns()\n",
    "\tt4 = t_GPUy_end - t_GPUy\n",
    "\t@printf(\"GPU through-put (Operator_y_GPU) %20.2f\\n\", 2* memsize * rep_times / t4)\n",
    "\n",
    "\treturn Float64(t1), Float64(t2), Float64(t3), Float64(t4)\n",
    "\n",
    "\treturn nothing\n",
    "end\n",
    "```\n",
    "\n",
    "```\n",
    "julia> tester_Operator_y_GPU(2000)\n",
    "Array(d_y) ≈ Array(y) = true\n",
    "Array(d2_y) ≈ Array(y2) = true\n",
    "CPU Through-put (Dy)                 2.41\n",
    "CPU Through-put (D2y)                 2.41\n",
    "CPU through-put (Dy + D2y, serial)                 1.21\n",
    "GPU through-put (D2y_GPU_v7)                96.95\n",
    "GPU through-put (Operator_y_GPU)                49.16\n",
    "(2.65638208e8, 2.61584846e8, 6.601347e6, 1.3019436e7)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Removing the step of assigning calculation results to Dy, only do calculation\n",
    "\n",
    "```\n",
    "julia> tester_Operator_y_GPU(2000)\n",
    "Array(d_y) ≈ Array(y) = false\n",
    "Array(d2_y) ≈ Array(y2) = true\n",
    "CPU Through-put (Dy)                 2.48\n",
    "CPU Through-put (D2y)                 2.48\n",
    "CPU through-put (Dy + D2y, serial)                 1.18\n",
    "GPU through-put (D2y_GPU_v7)                96.84\n",
    "GPU through-put (Operator_y_GPU)                80.08\n",
    "(2.58328058e8, 2.85296933e8, 6.608578e6, 7.991919e6)\n",
    "```\n",
    "\n",
    "\n",
    "The difference is obvious ...\n",
    "\n",
    "Loading two vector dy, d2_y and assign the results into them is very slow. Need better mechanism ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
