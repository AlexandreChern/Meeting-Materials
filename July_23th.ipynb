{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meeting July 23 nd\n",
    "\n",
    "## GPU Kernels for Matrix-free\n",
    "\n",
    "Basically just the translation of the CPU code\n",
    "\n",
    "Implementation for D2x or differental operators in x direction is fairly easy with nice performance. Speed-up compared to CPU iterative code is roughly 100x. Memory throughput is over 100 GB/s. Jeremy's well-optimzed GPU copy kernel can achieve something around 220 GB/s with shared_memory and tiling, so I guess this performance is close to optimal.\n",
    "\n",
    "But the problem is in the y direction. In GPU code, speed is mostly affected by how your optimize memory assignment. In operators associated with y directions, different threads will be working on non-adjacent grid point data, and it's very in-efficient. (the speedup decreases when the size of the matrix increases) I can't think of how to use tiling with shared memory in GPU copy and rotate kernel here.\n",
    "\n",
    "One approach is to restack u in a different direction and use D2x for D2y, then restack it back. Theoretically it's just a matrix rotation, and you can use shared memory for that, but doing so for each u twice is still far from efficient \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tester_D2x (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include(\"deriv_ops.jl\")\n",
    "\n",
    "using DataFrames\n",
    "using CUDA\n",
    "using Printf\n",
    "using StaticArrays\n",
    "using GPUifyLoops: @unroll\n",
    "\n",
    "\n",
    "function D2x(u, Nx, Ny, h)\n",
    "\tN = Nx*Ny\n",
    "\ty = zeros(N)\n",
    "\tidx = 1:Ny\n",
    "\ty[idx] = (u[idx] - 2 .* u[Ny .+ idx] + u[2*Ny .+ idx]) ./ h^2\n",
    "\n",
    "\tidx1 = Ny+1:N-Ny\n",
    "\ty[idx1] = (u[idx1 .- Ny] - 2 .* u[idx1] + u[idx1 .+ Ny]) ./ h^2\n",
    "\n",
    "\tidx2 = N-Ny+1:N\n",
    "\ty[idx2] = (u[idx2 .- 2*Ny] -2 .* u[idx2 .- Ny] + u[idx2]) ./ h^2\n",
    "\n",
    "\treturn y\n",
    "end\n",
    "\n",
    "function D2x_GPU(d_u, d_y, Nx, Ny, h, ::Val{TILE_DIM}) where {TILE_DIM}\n",
    "\ttidx = (blockIdx().x - 1) * TILE_DIM + threadIdx().x\n",
    "\tN = Nx*Ny\n",
    "\t# d_y = zeros(N)\n",
    "\tif tidx <= Ny\n",
    "\t\td_y[tidx] = (d_u[tidx] - 2 * d_u[Ny + tidx] + d_u[2*Ny + tidx]) / h^2\n",
    "\tend\n",
    "\tsync_threads()\n",
    "\n",
    "\tif Ny+1 <= tidx <= N-Ny\n",
    "\t\td_y[tidx] = (d_u[tidx - Ny] - 2 .* d_u[tidx] + d_u[tidx + Ny]) / h^2\n",
    "\tend\n",
    "\n",
    "\tsync_threads()\n",
    "\n",
    "\tif N-Ny+1 <= tidx <= N\n",
    "\t\td_y[tidx] = (d_u[tidx - 2*Ny] -2 * d_u[tidx - Ny] + d_u[tidx]) / h^2\n",
    "\tend\n",
    "\n",
    "\tnothing\n",
    "end\n",
    "\n",
    "function D2x_GPU_v2(d_u, d_y, Nx, Ny, h, ::Val{TILE_DIM}) where {TILE_DIM}\n",
    "\ttidx = (blockIdx().x - 1) * TILE_DIM + threadIdx().x\n",
    "\tN = Nx*Ny\n",
    "\t# d_y = zeros(N)\n",
    "\tif tidx <= Ny\n",
    "\t\td_y[tidx] = (d_u[tidx] - 2 * d_u[Ny + tidx] + d_u[2*Ny + tidx]) / h^2\n",
    "\tend\n",
    "\n",
    "\tif Ny+1 <= tidx <= N-Ny\n",
    "\t\td_y[tidx] = (d_u[tidx - Ny] - 2 .* d_u[tidx] + d_u[tidx + Ny]) / h^2\n",
    "\tend\n",
    "\n",
    "\n",
    "\tif N-Ny+1 <= tidx <= N\n",
    "\t\td_y[tidx] = (d_u[tidx - 2*Ny] -2 * d_u[tidx - Ny] + d_u[tidx]) / h^2\n",
    "\tend\n",
    "\n",
    "\tsync_threads()\n",
    "\n",
    "\tnothing\n",
    "end\n",
    "\n",
    "\n",
    "function tester_D2x(Nx)\n",
    "\t# Nx = Ny = 1000;\n",
    "\tNy = Nx\n",
    "\tu = randn(Nx * Ny)\n",
    "\td_u = CuArray(u)\n",
    "\td_y = similar(d_u)\n",
    "\th = 1/Nx\n",
    "\tTILE_DIM=32\n",
    "\tt1 = 0\n",
    "\tt2 = 0\n",
    "\tt3 = 0\n",
    "\n",
    "\trep_times = 10\n",
    "\n",
    "\tTHREAD_NUM = 32\n",
    "\tBLOCK_NUM = div(Nx * Ny,TILE_DIM) + 1\n",
    "\n",
    "\ty = D2x(u,Nx,Ny,h)\n",
    "\t@cuda threads=THREAD_NUM blocks=BLOCK_NUM D2x_GPU(d_u,d_y,Nx,Ny,h,Val(TILE_DIM))\n",
    "\ty_gpu = collect(d_y)\n",
    "\t@cuda threads=THREAD_NUM blocks=BLOCK_NUM D2x_GPU_v2(d_u,d_y,Nx,Ny,h,Val(TILE_DIM))\n",
    "\ty_gpu_2 = collect(d_y)\n",
    "\t@show y ≈ y_gpu\n",
    "\t@show y ≈ y_gpu_2\n",
    "\n",
    "\tty = time_ns()\n",
    "\tfor i in 1:rep_times\n",
    "\t\ty = D2x(u,Nx,Ny,h)\n",
    "\tend\n",
    "\tty_end = time_ns()\n",
    "\tt1 = ty_end - ty\n",
    "\tt_dy = time_ns()\n",
    "\tfor i in 1:rep_times\n",
    "\t\t@cuda threads=THREAD_NUM blocks=BLOCK_NUM D2x_GPU(d_u,d_y,Nx,Ny,h,Val(TILE_DIM))\n",
    "\tend\n",
    "\tsynchronize()\n",
    "\t# sync_threads()\n",
    "\tt_dy_end = time_ns()\n",
    "\tt2 = t_dy_end - t_dy\n",
    "\n",
    "\tt_dy_v2 = time_ns()\n",
    "\tfor i in 1:rep_times\n",
    "\t\t@cuda threads=THREAD_NUM blocks=BLOCK_NUM D2x_GPU_v2(d_u,d_y,Nx,Ny,h,Val(TILE_DIM))\n",
    "\tend\n",
    "\tsynchronize()\n",
    "\t# sync_threads()\n",
    "\tt_dy_v2_end = time_ns()\n",
    "\tt3 = t_dy_v2_end - t_dy_v2\n",
    "\n",
    "\t@show Float64(t1)\n",
    "\t@show Float64(t2)\n",
    "\t@show Float64(t3)\n",
    "\n",
    "\t@show t1/t2\n",
    "\t@show t1/t3\n",
    "\n",
    "\tmemsize = length(u) * sizeof(eltype(u))\n",
    "\t@printf(\"CPU Through-put %20.2f\\n\", 2 * memsize * rep_times / t1)\n",
    "\t@printf(\"GPU Through-put %20.2f\\n\", 2 * memsize * rep_times / t2)\n",
    "\t@printf(\"GPU (v2) Through-put %20.2f\\n\", 2 * memsize * rep_times / t3)\n",
    "\n",
    "\treturn Float64(t1), Float64(t2), Float64(t3)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y ≈ y_gpu = true\n",
      "y ≈ y_gpu_2 = true\n",
      "Float64(t1) = 1.739299e6\n",
      "Float64(t2) = 312900.0\n",
      "Float64(t3) = 271800.0\n",
      "t1 / t2 = 5.558641738574624\n",
      "t1 / t3 = 6.399186902133922\n",
      "CPU Through-put                 0.92\n",
      "GPU Through-put                 5.11\n",
      "GPU (v2) Through-put                 5.89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.739299e6, 312900.0, 271800.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester_D2x(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y ≈ y_gpu = true\n",
      "y ≈ y_gpu_2 = true\n",
      "Float64(t1) = 5.0142301e7\n",
      "Float64(t2) = 833000.0\n",
      "Float64(t3) = 660600.0\n",
      "t1 / t2 = 60.19483913565426\n",
      "t1 / t3 = 75.90417953375719\n",
      "CPU Through-put                 0.80\n",
      "GPU Through-put                48.02\n",
      "GPU (v2) Through-put                60.55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.0142301e7, 833000.0, 660600.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester_D2x(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y ≈ y_gpu = true\n",
      "y ≈ y_gpu_2 = true\n",
      "Float64(t1) = 3.55542001e8\n",
      "Float64(t2) = 2.1365e6\n",
      "Float64(t3) = 2.0478e6\n",
      "t1 / t2 = 166.41329323660193\n",
      "t1 / t3 = 173.62144789530228\n",
      "CPU Through-put                 0.45\n",
      "GPU Through-put                74.89\n",
      "GPU (v2) Through-put                78.13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.55542001e8, 2.1365e6, 2.0478e6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester_D2x(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y ≈ y_gpu = true\n",
      "y ≈ y_gpu_2 = true\n",
      "Float64(t1) = 2.11824347e10\n",
      "Float64(t2) = 1.71425101e8\n",
      "Float64(t3) = 1.338631e8\n",
      "t1 / t2 = 123.5667039216153\n",
      "t1 / t3 = 158.23953501749176\n",
      "CPU Through-put                 0.76\n",
      "GPU Through-put                93.34\n",
      "GPU (v2) Through-put               119.53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.11824347e10, 1.71425101e8, 1.338631e8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester_D2x(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also results from previous run-time\n",
    "\n",
    "```\n",
    "julia> tester_D2x(1000)\n",
    "y ≈ y_gpu = true\n",
    "y ≈ y_gpu_2 = true\n",
    "Float64(t1) = 1.95963799e8\n",
    "Float64(t2) = 2.2188e6\n",
    "Float64(t3) = 2.006499e6\n",
    "t1 / t2 = 88.31972192175951\n",
    "t1 / t3 = 97.66453858187819\n",
    "CPU Through-put                 0.82\n",
    "GPU Through-put                72.11\n",
    "GPU (v2) Through-put                79.74\n",
    "(1.95963799e8, 2.2188e6, 2.006499e6)\n",
    "\n",
    "julia> tester_D2x(2000)\n",
    "y ≈ y_gpu = true\n",
    "y ≈ y_gpu_2 = true\n",
    "Float64(t1) = 1.0486394e9\n",
    "Float64(t2) = 8.002999e6\n",
    "Float64(t3) = 7.609599e6\n",
    "t1 / t2 = 131.03080482704047\n",
    "t1 / t3 = 137.8048173103471\n",
    "CPU Through-put                 0.61\n",
    "GPU Through-put                79.97\n",
    "GPU (v2) Through-put                84.10\n",
    "(1.0486394e9, 8.002999e6, 7.609599e6)\n",
    "\n",
    "julia> tester_D2x(10000)\n",
    "y ≈ y_gpu = true\n",
    "y ≈ y_gpu_2 = true\n",
    "Float64(t1) = 2.40318696e10\n",
    "Float64(t2) = 1.807678e8\n",
    "Float64(t3) = 1.349505e8\n",
    "t1 / t2 = 132.94330959385465\n",
    "t1 / t3 = 178.07914457523313\n",
    "CPU Through-put                 0.67     \n",
    "GPU Through-put                88.51     \n",
    "GPU (v2) Through-put               118.56\n",
    "(2.40318696e10, 1.807678e8, 1.349505e8)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tester_D2y (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function D2y(u, Nx, Ny, h)\n",
    "\tN = Nx*Ny\n",
    "\ty = zeros(N)\n",
    "\tidx = 1:Ny:N-Ny+1\n",
    "\ty[idx] = (u[idx] - 2 .* u[idx .+ 1] + u[idx .+ 2]) ./ h^2\n",
    "\n",
    "\tidx1 = Ny:Ny:N\n",
    "\ty[idx1] = (u[idx1 .- 2] - 2 .* u[idx1 .- 1] + u[idx1]) ./ h^2\n",
    "\n",
    "\tfor j = 1:Nx\n",
    "\t\tidx = 2+(j-1)*Ny:j*Ny-1\n",
    "\t\ty[idx] = (u[idx .- 1] - 2 .* u[idx] + u[idx .+ 1]) ./ h^2\n",
    "\tend\n",
    "\n",
    "\treturn y\n",
    "\n",
    "end\n",
    "\n",
    "function D2y_GPU(d_u, d_y, Nx, Ny, h, ::Val{TILE_DIM}) where {TILE_DIM}\n",
    "\t# tidx = ((blockIdx().x - 1) * TILE_DIM + threadIdx().x - 1)*Ny + 1\n",
    "\ttidx = (blockIdx().x - 1) * TILE_DIM + threadIdx().x\n",
    "\tN = Nx*Ny\n",
    "\t# d_y = zeros(N)\n",
    "\tt1 = (tidx - 1)*Ny + 1\n",
    "\tif 1 <= t1 <= N - Ny + 1\n",
    "\t\td_y[t1] = (d_u[t1] - 2 * d_u[t1 + 1] + d_u[t1 + 2]) / h^2\n",
    "\tend\n",
    "\tsync_threads()\n",
    "\n",
    "\tt2 = tidx * Ny\n",
    "\tif Ny <= t2 <= N\n",
    "\t\td_y[t2] = (d_u[t2 - 2] - 2 * d_u[t2 - 1] + d_u[t2]) / h^2\n",
    "\tend\n",
    "\n",
    "\tsync_threads()\n",
    "\n",
    "\tfor j = 1:Nx\n",
    "\t\tif 2 + (j-1)*Ny <= tidx <= j*Ny-1\n",
    "\t\t\td_y[tidx] = (d_u[tidx - 1] - 2 * d_u[tidx] + d_u[tidx + 1]) / h^2\n",
    "\t\tend\n",
    "\tend\n",
    "\tsync_threads()\n",
    "\n",
    "\t# if N-Ny+1 <= tidx <= N\n",
    "\t# \td_y[tidx] = (d_u[tidx - 2*Ny] -2 * d_u[tidx - Ny] + d_u[tidx]) / h^2\n",
    "\t# end\n",
    "\n",
    "\tnothing\n",
    "end\n",
    "\n",
    "function D2y_GPU_v2(d_u, d_y, Nx, Ny, h, ::Val{TILE_DIM}) where {TILE_DIM}\n",
    "\t# tidx = ((blockIdx().x - 1) * TILE_DIM + threadIdx().x - 1)*Ny + 1\n",
    "\ttidx = (blockIdx().x - 1) * TILE_DIM + threadIdx().x\n",
    "\tN = Nx*Ny\n",
    "\t# d_y = zeros(N)\n",
    "\tt1 = (tidx - 1)*Ny + 1\n",
    "\tif 1 <= t1 <= N - Ny + 1\n",
    "\t\td_y[t1] = (d_u[t1] - 2 * d_u[t1 + 1] + d_u[t1 + 2]) / h^2\n",
    "\tend\n",
    "\n",
    "\n",
    "\tt2 = tidx * Ny\n",
    "\tif Ny <= t2 <= N\n",
    "\t\td_y[t2] = (d_u[t2 - 2] - 2 * d_u[t2 - 1] + d_u[t2]) / h^2\n",
    "\tend\n",
    "\n",
    "\tfor j = 1:Nx\n",
    "\t\tif 2 + (j-1)*Ny <= tidx <= j*Ny-1\n",
    "\t\t\td_y[tidx] = (d_u[tidx - 1] - 2 * d_u[tidx] + d_u[tidx + 1]) / h^2\n",
    "\t\tend\n",
    "\tend\n",
    "\n",
    "\t# if N-Ny+1 <= tidx <= N\n",
    "\t# \td_y[tidx] = (d_u[tidx - 2*Ny] -2 * d_u[tidx - Ny] + d_u[tidx]) / h^2\n",
    "\t# end\n",
    "\n",
    "\tnothing\n",
    "end\n",
    "\n",
    "function tester_D2y(Nx)\n",
    "\t# Nx = Ny = 1000;\n",
    "\tNy = Nx\n",
    "\tu = randn(Nx * Ny)\n",
    "\td_u = CuArray(u)\n",
    "\td_y = similar(d_u)\n",
    "\th = 1/Nx\n",
    "\tTILE_DIM=32\n",
    "\tt1 = 0\n",
    "\tt2 = 0\n",
    "\tt3 = 0\n",
    "\n",
    "\trep_times = 10\n",
    "\n",
    "\tTHREAD_NUM = 32\n",
    "\tBLOCK_NUM = div(Nx * Ny,TILE_DIM) + 1\n",
    "\n",
    "\ty = D2y(u,Nx,Ny,h)\n",
    "\t@cuda threads=THREAD_NUM blocks=BLOCK_NUM D2y_GPU(d_u,d_y,Nx,Ny,h,Val(TILE_DIM))\n",
    "\ty_gpu = collect(d_y)\n",
    "\t@cuda threads=THREAD_NUM blocks=BLOCK_NUM D2y_GPU_v2(d_u,d_y,Nx,Ny,h,Val(TILE_DIM))\n",
    "\ty_gpu_2 = collect(d_y)\n",
    "\t@show y ≈ y_gpu\n",
    "\t@show y ≈ y_gpu_2\n",
    "\n",
    "\tty = time_ns()\n",
    "\tfor i in 1:rep_times\n",
    "\t\ty = D2x(u,Nx,Ny,h)\n",
    "\tend\n",
    "\tty_end = time_ns()\n",
    "\tt1 = ty_end - ty\n",
    "\tt_dy = time_ns()\n",
    "\tfor i in 1:rep_times\n",
    "\t\t@cuda threads=THREAD_NUM blocks=BLOCK_NUM D2y_GPU(d_u,d_y,Nx,Ny,h,Val(TILE_DIM))\n",
    "\tend\n",
    "\tsynchronize()\n",
    "\t# sync_threads()\n",
    "\tt_dy_end = time_ns()\n",
    "\tt2 = t_dy_end - t_dy\n",
    "\n",
    "\tt_dy_v2 = time_ns()\n",
    "\tfor i in 1:rep_times\n",
    "\t\t@cuda threads=THREAD_NUM blocks=BLOCK_NUM D2y_GPU_v2(d_u,d_y,Nx,Ny,h,Val(TILE_DIM))\n",
    "\tend\n",
    "\tsynchronize()\n",
    "\t# sync_threads()\n",
    "\tt_dy_v2_end = time_ns()\n",
    "\tt3 = t_dy_v2_end - t_dy_v2\n",
    "\n",
    "\t@show Float64(t1)\n",
    "\t@show Float64(t2)\n",
    "\t@show Float64(t3)\n",
    "\n",
    "\t@show t1/t2\n",
    "\t@show t1/t3\n",
    "\n",
    "\tmemsize = length(u) * sizeof(eltype(u))\n",
    "\t@printf(\"CPU Through-put %20.2f\\n\", 2 * memsize * rep_times / t1)\n",
    "\t@printf(\"GPU Through-put %20.2f\\n\", 2 * memsize * rep_times / t2)\n",
    "\t@printf(\"GPU (v2) Through-put %20.2f\\n\", 2 * memsize * rep_times / t3)\n",
    "\n",
    "\treturn Float64(t1), Float64(t2), Float64(t3)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y ≈ y_gpu = true\n",
      "y ≈ y_gpu_2 = true\n",
      "Float64(t1) = 2.3381e6\n",
      "Float64(t2) = 425900.0\n",
      "Float64(t3) = 339799.0\n",
      "t1 / t2 = 5.489786334820381\n",
      "t1 / t3 = 6.8808324921497706\n",
      "CPU Through-put                 0.68\n",
      "GPU Through-put                 3.76\n",
      "GPU (v2) Through-put                 4.71\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.3381e6, 425900.0, 339799.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester_D2y(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y ≈ y_gpu = true\n",
      "y ≈ y_gpu_2 = true\n",
      "Float64(t1) = 4.17032e7\n",
      "Float64(t2) = 1.16499e7\n",
      "Float64(t3) = 1.12927e7\n",
      "t1 / t2 = 3.5797045468201443\n",
      "t1 / t3 = 3.6929343735333444\n",
      "CPU Through-put                 0.96\n",
      "GPU Through-put                 3.43\n",
      "GPU (v2) Through-put                 3.54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.17032e7, 1.16499e7, 1.12927e7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester_D2y(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y ≈ y_gpu = true\n",
      "y ≈ y_gpu_2 = true\n",
      "Float64(t1) = 1.72581301e8\n",
      "Float64(t2) = 7.91476e7\n",
      "Float64(t3) = 6.68384e7\n",
      "t1 / t2 = 2.180499484507427\n",
      "t1 / t3 = 2.5820681075549383\n",
      "CPU Through-put                 0.93\n",
      "GPU Through-put                 2.02\n",
      "GPU (v2) Through-put                 2.39\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.72581301e8, 7.91476e7, 6.68384e7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester_D2y(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y ≈ y_gpu = true\n",
      "y ≈ y_gpu_2 = true\n",
      "Float64(t1) = 2.07101086e10\n",
      "Float64(t2) = 6.1000083299e10\n",
      "Float64(t3) = 6.06608891e10\n",
      "t1 / t2 = 0.3395095134294597\n",
      "t1 / t3 = 0.34140793033645134\n",
      "CPU Through-put                 0.77\n",
      "GPU Through-put                 0.26\n",
      "GPU (v2) Through-put                 0.26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.07101086e10, 6.1000083299e10, 6.06608891e10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester_D2y(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from C++ Implementations from these two blogs\n",
    "\n",
    "### In X direction \n",
    "https://developer.nvidia.com/blog/finite-difference-methods-cuda-cc-part-1/<br>\n",
    "\n",
    "### In Y Z direction\n",
    "https://developer.nvidia.com/blog/finite-difference-methods-cuda-cc-part-1/<br>\n",
    "![GPU Results](graphics/GPU_finite_difference.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JuliaPro_v1.4.2-1 1.4.2",
   "language": "julia",
   "name": "juliapro_v1.4.2-1-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
